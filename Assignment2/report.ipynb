{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Assignment #2\n",
    "\n",
    "> ‚ú®\n",
    "> \n",
    "> `ü•ùName` \n",
    "> - Chenrui Fan\n",
    "> \n",
    "> `üçâStudent ID` \n",
    "> - 23-125-818\n",
    "> \n",
    "> `üçëGithub`\n",
    "> - https://github.com/Sosekie/DL_Assignment\n",
    "> \n",
    "> ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 ‚Äì Baseline\n",
    "\n",
    "The baseline consists of a simple convolutional image encoder followed by 2 RNN layers stacked\n",
    "vertically one on top of another. The RNN decodes the image code into a sequence of word\n",
    "tokens by treating the image code as the first input token (similar to a <SOS> token). The\n",
    "hidden state of the RNN is initialized with zeros. For more details refer to the code.\n",
    "\n",
    "### To Do \n",
    "\n",
    "The first task is to get familiar with the code base by training the baseline and\n",
    "calculating its BLEU scores (evaluating it on the validation set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Training the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreal_chenrui_fan\u001b[0m (\u001b[33mgood-pig\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./logs/model_1/wandb/run-20240510_195620-n8ugv7fh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodel_1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/good-pig/Assignment2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/good-pig/Assignment2/runs/n8ugv7fh\u001b[0m\n",
      "/home/fcr/anaconda3/envs/dl_a2/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B sync reduced upload amount by 22.2%             \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/cross_entropy_loss ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/cross_entropy_loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/cross_entropy_loss 2.92944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/cross_entropy_loss 3.53386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmodel_1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/good-pig/Assignment2/runs/n8ugv7fh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/good-pig/Assignment2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 200 media file(s), 689 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./logs/model_1/wandb/run-20240510_195620-n8ugv7fh/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python train.py --device-id=0 --config-file-path=./configs/config_model_1.yaml \\\n",
    "--experiment-name=model_1 --num-epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> calculating BLEU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "! python evaluate.py -d 0 --checkpoint-path=./checkpoints/model_1/model.pth.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "Although the baseline provides a simple and logical encoder/decoder architecture, it is often\n",
    "difficult to train such a system end-to-end. At the beginning of the training the image encoder\n",
    "does not extract useful information from the input image and the RNN has to hallucinate the\n",
    "output almost from nothing. Moreover, the training signal from the loss has to pass through\n",
    "all recurrent decoding iterations to reach the encoder. This complicates the training of the\n",
    "encoder and hence the whole model.\n",
    "\n",
    "To overcome this issue, following the good practices of representation and transfer learning, we\n",
    "propose to substitute the image encoder with a pre-trained network. Although this network\n",
    "can be further fine-tuned, this is not necessary, and it can be frozen for simplicity. As the\n",
    "image backbone, we suggest using DINOv2, as it is proven to have learned a great image\n",
    "representation\n",
    "\n",
    "### To Do \n",
    "\n",
    "Substitute the image backbone with DINOv2. Use the final <CLS> token from the\n",
    "DINOv2‚Äôs image representation as your image encoding. Freeze the backbone and\n",
    "train the decoder from scratch.\n",
    "\n",
    "Notice that thanks to the modular implementation, to solve this task, it is sufficient\n",
    "to change only the encoder‚Äôs code.\n",
    "\n",
    "Explore the official DINOv2‚Äôs GitHub to see how to load and use the pre-trained\n",
    "models. Tutorial 10 may also help you with this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using DINOv2 as encoder and train the decoder from scratch, freeze() is called in train.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fcr/.cache/torch/hub/facebookresearch_dinov2_main    \n",
      "/home/fcr/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/fcr/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/fcr/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreal_chenrui_fan\u001b[0m (\u001b[33mgood-pig\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./logs/model_2/wandb/run-20240510_205422-t4wclfvi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodel_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/good-pig/Assignment2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/good-pig/Assignment2/runs/t4wclfvi\u001b[0m\n",
      "/home/fcr/anaconda3/envs/dl_a2/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Epoch 24 | train:  40%|‚ñç| 56/139 [00:13<00:14,  5.70batch/s, cross_entropy_loss:^C\n",
      "Traceback (most recent call last):                                              \n",
      "  File \"/mnt/f/GitHub/DL_Assignment/Assignment2/train.py\", line 81, in <module>\n",
      "    main(args=args, config=config)\n",
      "  File \"/mnt/f/GitHub/DL_Assignment/Assignment2/train.py\", line 69, in main\n",
      "    trainer.train(train_dataloader=train_dataloader,\n",
      "  File \"/mnt/f/GitHub/DL_Assignment/Assignment2/training/trainer.py\", line 25, in train\n",
      "    self.run_epoch(dataloader=train_dataloader, epoch=epoch, phase='train')\n",
      "  File \"/mnt/f/GitHub/DL_Assignment/Assignment2/training/trainer.py\", line 44, in run_epoch\n",
      "    loss += objective.item()\n",
      "            ^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! python train.py --device-id=0 --config-file-path=./configs/config_model_2.yaml \\\n",
    "--experiment-name=model_2 --num-epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> calculating BLEU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python evaluate.py -d 0 --checkpoint-path=./checkpoints/model_2/model.pth.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "We know that DINOv2 provides a great signal. So, in order to improve the model, we need to\n",
    "modify the decoder. A simple RNN seems not a great choice. What about one of the gated\n",
    "recurrent counterparts discussed in the lectures and the tutorials?\n",
    "\n",
    "### To Do \n",
    "\n",
    "Given the encoder from Model 2, replace the RNN in the decoder with a gated\n",
    "recurrency (LSTM, GRU, etc.). Train the model and try different number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --device-id=0 --config-file-path=./configs/config_model_3.yaml \\\n",
    "--experiment-name=model_3 --num-epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
